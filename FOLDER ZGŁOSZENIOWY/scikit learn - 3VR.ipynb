{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d0f425ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "sequential_data = np.load(\"Signals.npz\", allow_pickle=True)[\"a\"].item()\n",
    "train_data = pd.read_csv(\"metadata_train.csv\")\n",
    "\n",
    "#test_data = pd.read_csv(\"metadata_test.csv\")\n",
    "\n",
    "y = train_data['CycleToFailureNormalized']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2c7f6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = train_data[\"SignalID\"].to_numpy()\n",
    "tab1 = []\n",
    "\n",
    "dlugosc = []\n",
    "max_val = []\n",
    "min_val = []\n",
    "\n",
    "#for smallest(a) to highest(e) of values\n",
    "amount_e = []\n",
    "amount_d = []\n",
    "amount_c = []\n",
    "amount_b = []\n",
    "amount_a = []\n",
    "\n",
    "#for smallest(a) to highest(e) of values\n",
    "density_amount_e = []\n",
    "density_amount_d = []\n",
    "density_amount_c = []\n",
    "density_amount_b = []\n",
    "density_amount_a = []\n",
    "\n",
    "#for smallest(a) to highest(d) of values\n",
    "num_of_a_changes = []\n",
    "num_of_b_changes = []\n",
    "num_of_c_changes = []\n",
    "num_of_d_changes = []\n",
    "\n",
    "# standard deviation\n",
    "std = []\n",
    "extreme_changes = []\n",
    "std_a = []\n",
    "std_b = []\n",
    "std_c = []\n",
    "std_d = []\n",
    "\n",
    "for x in train_index:\n",
    "    tab1.append(sequential_data[x])\n",
    "    dlugosc.append(len(sequential_data[x]))\n",
    "    max_val.append(np.amax(sequential_data[x],axis=0))\n",
    "    min_val.append(np.amin(sequential_data[x],axis=0))\n",
    "\n",
    "    amount_e.append((sequential_data[x] >20650).sum())\n",
    "    amount_d.append(((15000<=sequential_data[x]) &(sequential_data[x] <=20650)).sum())\n",
    "    amount_c.append(((12500<=sequential_data[x]) &(sequential_data[x] <20650)).sum())\n",
    "    amount_b.append(((2500<=sequential_data[x]) &(sequential_data[x] <10000)).sum())\n",
    "    amount_a.append((sequential_data[x] <0).sum())\n",
    "\n",
    "    density_amount_e.append(((20750<=sequential_data[x])).sum()/len(sequential_data[x]))\n",
    "    density_amount_d.append(((15000<=sequential_data[x]) &(sequential_data[x] <=20750)).sum()/len(sequential_data[x]))\n",
    "    density_amount_c.append(((9500<=sequential_data[x]) &(sequential_data[x] <15000)).sum()/len(sequential_data[x]))\n",
    "    density_amount_b.append(((5000<=sequential_data[x]) &(sequential_data[x] <9500)).sum()/len(sequential_data[x]))\n",
    "    density_amount_a.append(((0<sequential_data[x]) &(sequential_data[x] <5000)).sum()/len(sequential_data[x]))\n",
    "\n",
    "    num_of_a_changes.append(((0<np.absolute(np.diff(sequential_data[x]))) &(np.absolute(np.diff(sequential_data[x]) <=155))).sum())\n",
    "    num_of_b_changes.append(((1500<np.absolute(np.diff(sequential_data[x]))) &(np.absolute(np.diff(sequential_data[x]) <=2500))).sum())\n",
    "    num_of_c_changes.append(((2500<np.absolute(np.diff(sequential_data[x]))) &(np.absolute(np.diff(sequential_data[x]) <=4000))).sum())\n",
    "    num_of_d_changes.append(((4000<np.absolute(np.diff(sequential_data[x])))).sum())\n",
    "\n",
    "    A,B,C = np.array_split(sequential_data[x],3)\n",
    "    std_a.append(np.std(A,axis=0))\n",
    "    std_b.append(np.std(B,axis=0))\n",
    "    std_c.append(np.std(C,axis=0))\n",
    "    #std_d.append(np.std(D,axis=0))\n",
    "\n",
    "    a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,r,s,t,u = np.array_split(sequential_data[x],20)\n",
    "    std = np.array([np.std(a,axis=0),np.std(b,axis=0),np.std(c,axis=0),np.std(d,axis=0),np.std(e,axis=0),np.std(f,axis=0),np.std(g,axis=0),np.std(h,axis=0),np.std(i,axis=0),np.std(j,axis=0),\n",
    "                    np.std(k,axis=0),np.std(l,axis=0),np.std(m,axis=0),np.std(n,axis=0),np.std(o,axis=0),\n",
    "                    np.std(p,axis=0),np.std(r,axis=0),np.std(s,axis=0),np.std(t,axis=0),np.std(u,axis=0)])\n",
    "\n",
    "    if (np.max(std)-np.min(std))>8000:\n",
    "        extreme_changes.append(int(np.max(std)-np.min(std)))\n",
    "    else:\n",
    "        extreme_changes.append(int(0))\n",
    " \n",
    "train_data[\"dlugosc\"] = dlugosc\n",
    "train_data[\"max_val\"] = max_val\n",
    "train_data[\"min_val\"] = min_val\n",
    "\n",
    "train_data[\"1/4 odchylenie standardowe\"] = std_a\n",
    "train_data[\"2/4 odchylenie standardowe\"] = std_b\n",
    "train_data[\"3/4 odchylenie standardowe\"] = std_c\n",
    "#train_data[\"4/4 odchylenie standardowe\"] = std_d\n",
    "\n",
    "\n",
    "train_data[\"amount_e\"] = amount_e\n",
    "train_data[\"amount_d\"] = amount_d\n",
    "train_data[\"amount_c\"] = amount_c\n",
    "train_data[\"amount_b\"] = amount_b\n",
    "train_data[\"amount_a\"] = amount_a\n",
    "\n",
    "train_data[\"density_amount_e\"] = density_amount_e\n",
    "train_data[\"density_amount_d\"] = density_amount_d\n",
    "train_data[\"density_amount_c\"] = density_amount_c\n",
    "train_data[\"density_amount_b\"] = density_amount_b\n",
    "train_data[\"density_amount_a\"] = density_amount_a\n",
    "\n",
    "train_data[\"num_of_a_changes\"] = num_of_a_changes\n",
    "train_data[\"num_of_b_changes\"] = num_of_b_changes\n",
    "train_data[\"num_of_c_changes\"] = num_of_c_changes\n",
    "train_data[\"num_of_d_changes\"] = num_of_d_changes\n",
    "\n",
    "train_data[\"extreme_changes\"] = extreme_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50a534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "51f9692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W POSZUKIWANIU KORELACJI (PEARSON)\n",
      "\n",
      "\n",
      "CycleToFailureNormalized      1.000000\n",
      "density_amount_a              0.477482\n",
      "density_amount_b              0.415135\n",
      "min_val                       0.272281\n",
      "amount_b                      0.269452\n",
      "num_of_a_changes              0.096175\n",
      "dlugosc                       0.054364\n",
      "HardnessMean [HRC]            0.036656\n",
      "RDOC [mm]                     0.001255\n",
      "ToolIndex                    -0.002362\n",
      "ADOC [mm]                    -0.012465\n",
      "ToolHolderLength [mm]        -0.017388\n",
      "amount_a                     -0.173562\n",
      "1/4 odchylenie standardowe   -0.194780\n",
      "num_of_b_changes             -0.257065\n",
      "num_of_d_changes             -0.267399\n",
      "num_of_c_changes             -0.355111\n",
      "extreme_changes              -0.358232\n",
      "SignalID                     -0.366419\n",
      "amount_d                     -0.370394\n",
      "density_amount_d             -0.397599\n",
      "density_amount_c             -0.404072\n",
      "density_amount_e             -0.419552\n",
      "amount_e                     -0.425769\n",
      "amount_c                     -0.440309\n",
      "2/4 odchylenie standardowe   -0.512773\n",
      "3/4 odchylenie standardowe   -0.544385\n",
      "max_val                      -0.549182\n",
      "ToolRotation [rpm]                 NaN\n",
      "FeedRate [mm/min]                  NaN\n",
      "ToolDiameter [mm]                  NaN\n",
      "Name: CycleToFailureNormalized, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = train_data['CycleToFailureNormalized']\n",
    "\n",
    "\n",
    "corr_matrix = train_data.corr()\n",
    "print(\"W POSZUKIWANIU KORELACJI (PEARSON)\")\n",
    "print(\"\\n\")\n",
    "print(corr_matrix[\"CycleToFailureNormalized\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a0f9591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data\n",
    "\n",
    "####################################################################################\n",
    "# PORZUCANIE SŁABO SKORELOWANYCH ZMIENNYCH \n",
    "\n",
    "#train_data.drop('CycleToFailureNormalized', inplace=True, axis=1)\n",
    "#train_data.drop('ToolRotation [rpm]', inplace=True, axis=1)\n",
    "#train_data.drop('FeedRate [mm/min]', inplace=True, axis=1)\n",
    "#train_data.drop('ToolIndex', inplace=True, axis=1)\n",
    "#train_data.drop('RDOC [mm]', inplace=True, axis=1)\n",
    "#train_data.drop('ToolDiameter [mm]', inplace=True, axis=1)\n",
    "#train_data.drop('ADOC [mm]', inplace=True, axis=1)\n",
    "#train_data.drop('ToolHolderLength [mm]', inplace=True, axis=1)\n",
    "#train_data.drop('max_val', inplace=True, axis=1)\n",
    "#train_data.drop('min_val', inplace=True, axis=1)\n",
    "\n",
    "#print(train_data.shape)\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ab98b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W POSZUKIWANIU KORELACJI (PEARSON)\n",
      "\n",
      "\n",
      "CycleToFailureNormalized      1.000000\n",
      "density_amount_a              0.477482\n",
      "density_amount_b              0.415135\n",
      "min_val                       0.272281\n",
      "amount_b                      0.269452\n",
      "num_of_a_changes              0.096175\n",
      "dlugosc                       0.054364\n",
      "HardnessMean [HRC]            0.036656\n",
      "RDOC [mm]                     0.001255\n",
      "ToolIndex                    -0.002362\n",
      "ADOC [mm]                    -0.012465\n",
      "ToolHolderLength [mm]        -0.017388\n",
      "amount_a                     -0.173562\n",
      "1/4 odchylenie standardowe   -0.194780\n",
      "num_of_b_changes             -0.257065\n",
      "num_of_d_changes             -0.267399\n",
      "num_of_c_changes             -0.355111\n",
      "extreme_changes              -0.358232\n",
      "SignalID                     -0.366419\n",
      "amount_d                     -0.370394\n",
      "density_amount_d             -0.397599\n",
      "density_amount_c             -0.404072\n",
      "density_amount_e             -0.419552\n",
      "amount_e                     -0.425769\n",
      "amount_c                     -0.440309\n",
      "2/4 odchylenie standardowe   -0.512773\n",
      "3/4 odchylenie standardowe   -0.544385\n",
      "max_val                      -0.549182\n",
      "ToolRotation [rpm]                 NaN\n",
      "FeedRate [mm/min]                  NaN\n",
      "ToolDiameter [mm]                  NaN\n",
      "Name: CycleToFailureNormalized, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = train_data.corr()\n",
    "print(\"W POSZUKIWANIU KORELACJI (PEARSON)\")\n",
    "print(\"\\n\")\n",
    "print(corr_matrix[\"CycleToFailureNormalized\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9516a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ADOC [mm]  RDOC [mm]  HardnessMean [HRC]  ToolHolderLength [mm]  \\\n",
      "0          5        8.0               36.67                     80   \n",
      "1          5        8.0               36.67                     80   \n",
      "2          5        8.0               36.67                     80   \n",
      "3          5        8.0               36.67                     80   \n",
      "4          5        8.0               36.67                     80   \n",
      "\n",
      "   ToolRotation [rpm]  FeedRate [mm/min]  ToolDiameter [mm]  dlugosc  max_val  \\\n",
      "0                3200                640                 10    53965    12854   \n",
      "1                3200                640                 10    31815    13385   \n",
      "2                3200                640                 10    40706    18546   \n",
      "3                3200                640                 10    36637     9360   \n",
      "4                3200                640                 10    56097    15579   \n",
      "\n",
      "   min_val  ...  density_amount_e  density_amount_d  density_amount_c  \\\n",
      "0      296  ...               0.0          0.000000          0.085240   \n",
      "1      283  ...               0.0          0.000000          0.091089   \n",
      "2      292  ...               0.0          0.009802          0.044220   \n",
      "3      287  ...               0.0          0.000000          0.000000   \n",
      "4      288  ...               0.0          0.003565          0.098151   \n",
      "\n",
      "   density_amount_b  density_amount_a  num_of_a_changes  num_of_b_changes  \\\n",
      "0          0.461484          0.453275               436                 9   \n",
      "1          0.399623          0.509288               253                 7   \n",
      "2          0.280204          0.665774               323                 9   \n",
      "3          0.338674          0.661326               278                 8   \n",
      "4          0.440451          0.457832               452                16   \n",
      "\n",
      "   num_of_c_changes  num_of_d_changes  extreme_changes  \n",
      "0                 1                 1                0  \n",
      "1                 6                 1                0  \n",
      "2                 7                 2                0  \n",
      "3                 0                 1                0  \n",
      "4                 4                 3                0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(X.head())\n",
    "X.drop('CycleToFailureNormalized', inplace=True, axis=1)\n",
    "X.drop('SignalID', inplace=True, axis=1)\n",
    "X.drop('ToolIndex', inplace=True, axis=1)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e6b174ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 28)\n",
      "(554, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1, random_state= None)\n",
    "\n",
    "#print(X_train.shape); print(X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\"\"\"\n",
    "\n",
    "Scaler = MinMaxScaler()\n",
    "Scaler.fit(X_train)\n",
    "X_train = Scaler.transform(X_train)\n",
    "X_test = Scaler.transform(X_test)\n",
    "\n",
    "\n",
    "############################################################3\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "#print(X_train.mean(axis=0))\n",
    "#print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ffd7371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='r2',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    \n",
    "    if do_probabilities:\n",
    "      pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "      pred = fitted_model.predict(X_test_data)\n",
    "    \n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "901a7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = ExtraTreesRegressor()\\nparam_grid = {\\n    'n_estimators': [100,150,300],\\n    'min_samples_split': [2,4,8,12],\\n    'max_depth':[10,20,35,50],\\n    'min_samples_leaf':[2,3,4],\\n    'n_jobs':[-1,3,5,10]\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit='r2')\\n\\nprint(model.best_score_)\\nprint(model.best_params_) \""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = ExtraTreesRegressor(n_estimators=100, n_jobs=4, min_samples_split=25,\n",
    "#                            min_samples_leaf=35, max_features=150)\n",
    "\n",
    "\"\"\"model = ExtraTreesRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150,300],\n",
    "    'min_samples_split': [2,4,8,12],\n",
    "    'max_depth':[10,20,35,50],\n",
    "    'min_samples_leaf':[2,3,4],\n",
    "    'n_jobs':[-1,3,5,10]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_) \"\"\"                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "85fd42ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = RandomForestRegressor()\\nparam_grid = {\\n    \\'n_estimators\\': [60,75,100,110],\\n    \\'max_depth\\':[10,20,25,30],\\n    \\'n_jobs\\':[3,5,6,7],\\n    \\'min_samples_leaf\\': [1,3,5,10]\\n\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n\\nRFR = RandomForestRegressor(n_estimators= 100, max_depth=30, n_jobs=5, min_samples_split=2,min_samples_leaf=1)\\n                           \\nRFR.fit(X_train, y_train)\\npred5 = RFR.predict(X_test)\\nprint(\"Accuracy on test set for RFR: %.2f\" % (r2_score(y_test, pred5) * 100))'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = RandomForestRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [60,75,100,110],\n",
    "    'max_depth':[10,20,25,30],\n",
    "    'n_jobs':[3,5,6,7],\n",
    "    'min_samples_leaf': [1,3,5,10]\n",
    "\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\n",
    "RFR = RandomForestRegressor(n_estimators= 100, max_depth=30, n_jobs=5, min_samples_split=2,min_samples_leaf=1)\n",
    "                           \n",
    "RFR.fit(X_train, y_train)\n",
    "pred5 = RFR.predict(X_test)\n",
    "print(\"Accuracy on test set for RFR: %.2f\" % (r2_score(y_test, pred5) * 100))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d043cd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = XGBRegressor()\\nparam_grid = {\\n    \\'n_estimators\\': [150,300,400,500],\\n    \\'min_samples_split\\': [2,3,4],\\n    \\'max_depth\\':[5,10,15,20],\\n    \\'learning_rate\\': [0.2,0.15,0.25,0.12],\\n    \\'subsample\\':[0.95,0.9,0.85]\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n###################################################################################\\n\\nXGB = XGBRegressor(base_score=0.5, booster=\\'gbtree\\', colsample_bylevel=1,\\n             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\\n             gamma=0, gpu_id=-1, importance_type=None,\\n             interaction_constraints=\\'\\', learning_rate=0.12, max_delta_step=0,\\n             max_depth=5, min_child_weight=1, min_samples_split=2, missing=nan,\\n             monotone_constraints=\\'()\\', n_estimators=300, n_jobs=4,\\n             num_parallel_tree=1, predictor=\\'auto\\', random_state=0, reg_alpha=0,\\n             reg_lambda=1, scale_pos_weight=1, subsample=0.85,\\n             tree_method=\\'exact\\', validate_parameters=1, verbosity=None)\\nXGB = XGB.fit(X_train, y_train)\\npred2 = XGB.predict(X_test)\\nprint(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred2)*100))'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [150,300,400,500],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'max_depth':[5,10,15,20],\n",
    "    'learning_rate': [0.2,0.15,0.25,0.12],\n",
    "    'subsample':[0.95,0.9,0.85]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "XGB = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.12, max_delta_step=0,\n",
    "             max_depth=5, min_child_weight=1, min_samples_split=2, missing=nan,\n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=0.85,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "XGB = XGB.fit(X_train, y_train)\n",
    "pred2 = XGB.predict(X_test)\n",
    "print(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred2)*100))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d12395d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = svm.SVR()\\nparam_grid = {\\n    \\'degree\\': [2,3,4,5,6],\\n    #\\'kernel\\': [\"poly\",\"rbf\",\"sigmoid\",\"precomputed\"],\\n    \"C\":[0.8,0.9,1,1.1,1.2]\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n###################################################################################\\n\\nSVR = svm.SVR(C=1.2, degree=2)\\nSVR = SVR.fit(X_train, y_train)\\npred2 = SVR.predict(X_test)\\nprint(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred2)*100))'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = svm.SVR()\n",
    "param_grid = {\n",
    "    'degree': [2,3,4,5,6],\n",
    "    #'kernel': [\"poly\",\"rbf\",\"sigmoid\",\"precomputed\"],\n",
    "    \"C\":[0.8,0.9,1,1.1,1.2]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "SVR = svm.SVR(C=1.2, degree=2)\n",
    "SVR = SVR.fit(X_train, y_train)\n",
    "pred2 = SVR.predict(X_test)\n",
    "print(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred2)*100))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c40f7c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model =  DecisionTreeRegressor()\\n\\nparam_grid = {\\n    \\'min_samples_split\\': [4,6,10,12],\\n    \\'max_depth\\':[5,10,15,20,30],\\n    \\'max_leaf_nodes\\':[100,200,300]\\n    }\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n###################################################################################\\n\\nDecisionTreeRegressor(max_depth=15, max_leaf_nodes=300, min_samples_split=10)\\n\\nDTR = DecisionTreeRegressor(max_depth=15, max_leaf_nodes=300, min_samples_split=10)\\nDTR = DTR.fit(X_train, y_train)\\npred2 = DTR.predict(X_test)\\nprint(\"Accuracy on test set for KNF: %.2f\" % (r2_score(y_test, pred2)*100))'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model =  DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [4,6,10,12],\n",
    "    'max_depth':[5,10,15,20,30],\n",
    "    'max_leaf_nodes':[100,200,300]\n",
    "    }\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "DecisionTreeRegressor(max_depth=15, max_leaf_nodes=300, min_samples_split=10)\n",
    "\n",
    "DTR = DecisionTreeRegressor(max_depth=15, max_leaf_nodes=300, min_samples_split=10)\n",
    "DTR = DTR.fit(X_train, y_train)\n",
    "pred2 = DTR.predict(X_test)\n",
    "print(\"Accuracy on test set for KNF: %.2f\" % (r2_score(y_test, pred2)*100))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "def9db5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model =   KNeighborsRegressor(leaf_size=1,n_neighbors=20,n_jobs=-1)\\nparam_grid = {\\n    \\'n_jobs\\': [-1,1,2,3,4],\\n    \\'n_neighbors\\': [20,40,50,70,80,100,150],\\n    \\'leaf_size\\':[1,2,5,7,8,9,10,],\\n    \\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n###################################################################################\\n#KNeighborsRegressor(leaf_size=1, n_jobs=-1, n_neighbors=20)\\n\\nKNF = KNeighborsRegressor(leaf_size=1, n_jobs=-1, n_neighbors=20)\\nKNF = KNF.fit(X_train, y_train)\\npred2 = KNF.predict(X_test)\\nprint(\"Accuracy on test set for KNF: %.2f\" % (r2_score(y_test, pred2)*100))'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model =   KNeighborsRegressor(leaf_size=1,n_neighbors=20,n_jobs=-1)\n",
    "param_grid = {\n",
    "    'n_jobs': [-1,1,2,3,4],\n",
    "    'n_neighbors': [20,40,50,70,80,100,150],\n",
    "    'leaf_size':[1,2,5,7,8,9,10,],\n",
    "    \n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "###################################################################################\n",
    "#KNeighborsRegressor(leaf_size=1, n_jobs=-1, n_neighbors=20)\n",
    "\n",
    "KNF = KNeighborsRegressor(leaf_size=1, n_jobs=-1, n_neighbors=20)\n",
    "KNF = KNF.fit(X_train, y_train)\n",
    "pred2 = KNF.predict(X_test)\n",
    "print(\"Accuracy on test set for KNF: %.2f\" % (r2_score(y_test, pred2)*100))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0b36bee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nmodel = GradientBoostingRegressor()\\nparam_grid = {\\n    \\'n_estimators\\': [150,300,400,500],\\n    \\'min_samples_split\\': [2,3,4],\\n    \\'max_depth\\':[5,10,20,30],\\n    \\'learning_rate\\': [0.2,0.15,0.25,0.12],\\n    \\'subsample\\':[0.95,0.9,0.85]\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit=\\'r2\\')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n###################################################################################\\n\\nGBR = GradientBoostingRegressor(max_depth= 5, learning_rate = 0.12, n_estimators = 500,\\n                                subsample=0.85,n_jobs=-1,min_samples_split=2)\\nGBR = GBR.fit(X_train, y_train)\\npred2 = GBR.predict(X_test)\\nprint(\"Accuracy on test set for GBR: %.2f\" % (r2_score(y_test, pred2)*100))\\n\\n#0.840953694351283\\n#{\\'learning_rate\\': 0.12, \\'max_depth\\': 5, \\'min_samples_split\\': 2, \\'n_estimators\\': 500, \\'subsample\\': 0.85}\\n'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [150,300,400,500],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'max_depth':[5,10,20,30],\n",
    "    'learning_rate': [0.2,0.15,0.25,0.12],\n",
    "    'subsample':[0.95,0.9,0.85]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "GBR = GradientBoostingRegressor(max_depth= 5, learning_rate = 0.12, n_estimators = 500,\n",
    "                                subsample=0.85,n_jobs=-1,min_samples_split=2)\n",
    "GBR = GBR.fit(X_train, y_train)\n",
    "pred2 = GBR.predict(X_test)\n",
    "print(\"Accuracy on test set for GBR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "#0.840953694351283\n",
    "#{'learning_rate': 0.12, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.85}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f797eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set for RFR: 79.21\n",
      "Accuracy on test set for DTR: 42.91\n",
      "Accuracy on test set for KNR: 69.34\n",
      "Accuracy on test set for SVR: 77.58\n",
      "Accuracy on test set for ETR: 83.25\n",
      "Accuracy on test set for XGB: 83.45\n",
      "Accuracy on test set for GBR: 83.64\n",
      "Accuracy on test set for CBR: 76.06\n",
      "Accuracy on test set for LGBM: 76.66\n",
      "Accuracy on test set for VR2: 82.98\n",
      "Accuracy on test set for VR3: 84.33\n",
      "Accuracy on test set for VR4: 82.90\n"
     ]
    }
   ],
   "source": [
    "RFR = RandomForestRegressor(n_estimators= 100, max_depth=30, n_jobs=5, min_samples_split=2,min_samples_leaf=1)\n",
    "                           \n",
    "RFR.fit(X_train, y_train)\n",
    "pred5 = RFR.predict(X_test)\n",
    "print(\"Accuracy on test set for RFR: %.2f\" % (r2_score(y_test, pred5) * 100))\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "DTR = DecisionTreeRegressor(max_depth=15, max_leaf_nodes=300, min_samples_split=10)\n",
    "DTR = DTR.fit(X_train, y_train)\n",
    "pred2 = DTR.predict(X_test)\n",
    "print(\"Accuracy on test set for DTR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "KNR = KNeighborsRegressor(leaf_size=1, n_jobs=-1, n_neighbors=20)\n",
    "KNR = KNR.fit(X_train, y_train)\n",
    "pred2 = KNR.predict(X_test)\n",
    "print(\"Accuracy on test set for KNR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "SVR = svm.SVR(C=1.2, degree=2)\n",
    "SVR = SVR.fit(X_train, y_train)\n",
    "pred2 = SVR.predict(X_test)\n",
    "print(\"Accuracy on test set for SVR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "ETR =  ExtraTreesRegressor(n_estimators=100,max_depth=20,n_jobs=3,min_samples_split=2)\n",
    "                           \n",
    "ETR.fit(X_train, y_train)\n",
    "pred8 = ETR.predict(X_test)\n",
    "print(\"Accuracy on test set for ETR: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': 3}\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "XGB = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
    "             gamma=0, gpu_id=-1, importance_type=None,\n",
    "             interaction_constraints='', learning_rate=0.12, max_delta_step=0,\n",
    "             max_depth=5, min_child_weight=1,\n",
    "             monotone_constraints='()', n_estimators=300, n_jobs=4,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=0.85,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "XGB = XGB.fit(X_train, y_train)\n",
    "pred2 = XGB.predict(X_test)\n",
    "print(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "GBR = GradientBoostingRegressor(max_depth= 5, learning_rate = 0.12, n_estimators = 500,\n",
    "                                subsample=0.85,min_samples_split=2)\n",
    "GBR = GBR.fit(X_train, y_train)\n",
    "pred2 = GBR.predict(X_test)\n",
    "print(\"Accuracy on test set for GBR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "#######################################################################################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "CBR =  CatBoostRegressor(\n",
    "    learning_rate= 0.005,\n",
    "    depth=4,\n",
    "    l2_leaf_reg= 1,\n",
    "    verbose = False,\n",
    "    early_stopping_rounds= 200)\n",
    "                           \n",
    "CBR.fit(X_train, y_train)\n",
    "pred8 = CBR.predict(X_test)\n",
    "print(\"Accuracy on test set for CBR: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "LGBM =  LGBMRegressor( num_leaves= 39,\n",
    "    max_depth= 2,\n",
    "    learning_rate= 0.13705339989856127,\n",
    "    n_estimators= 273)\n",
    "                           \n",
    "LGBM.fit(X_train, y_train)\n",
    "pred8 = LGBM.predict(X_test)\n",
    "print(\"Accuracy on test set for LGBM: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "# estimators = [('a', SVR), ('b', ETR), ('C', GBR),('E',XGB )] # VR:0.858 // STACK:0.841 \n",
    "# estimators = [('a', SVR), ('b', ETR), ('C', GBR),('E',XGB )] # VR:0.847 // STACK:0.846 \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "VR = VotingRegressor([('a', SVR), ('b', ETR), ('C', GBR),('E',XGB )],weights=(0.15,0.7,0.2,0.25))\n",
    "VR = VR.fit(X_train, y_train)\n",
    "pred2 = VR.predict(X_test)\n",
    "print(\"Accuracy on test set for VR: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "VR1 = VotingRegressor([('a',  SVR), ('b', ETR), ('C', GBR),('E',CBR )],weights=(0.15,0.7,0.2,0.25))\n",
    "VR1 = VR1.fit(X_train, y_train)\n",
    "pred2 = VR1.predict(X_test)\n",
    "print(\"Accuracy on test set for VR1: %.2f\" % (r2_score(y_test, pred2)*100))\\\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "VR2 = VotingRegressor([('a',  SVR), ('b', ETR), ('C', GBR),('D',LGBM ),('E',XGB )],weights=(0.1,0.7,0.12,0.25,0.3))\n",
    "VR2 = VR2.fit(X_train, y_train)\n",
    "pred2 = VR2.predict(X_test)\n",
    "print(\"Accuracy on test set for VR2: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "VR3 = VotingRegressor([('a',  SVR), ('b', ETR), ('C', GBR),('D',LGBM ),('E',XGB )],weights=(0.05,0.5,0.12,0.15,0.2))\n",
    "VR3 = VR3.fit(X_train, y_train)\n",
    "pred2 = VR3.predict(X_test)\n",
    "print(\"Accuracy on test set for VR3: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "\n",
    "\n",
    "VR4 = VotingRegressor([('b', ETR), ('C', GBR),('D',LGBM ),('E',XGB )],weights=(0.7,0.12,0.25,0.3))\n",
    "VR4 = VR4.fit(X_train, y_train)\n",
    "pred2 = VR4.predict(X_test)\n",
    "print(\"Accuracy on test set for VR4: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "\n",
    "#VR3 = VotingRegressor([('a',  SVR), ('b', ETR), ('C', GBR),('D',LGBM ),('E',XGB ),('F',CBR )],weights=(0.15,0.7,0.25,0.2,0.1,0.1))\n",
    "#VR3= VR3.fit(X_train, y_train)\n",
    "#pred2 = VR3.predict(X_test)\n",
    "#print(\"Accuracy on test set for VR3: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "#estimators = [('a', SVR), ('b', ETR), ('C',GBR),('E',XGB )]\n",
    "#STACK= StackingRegressor(estimators=estimators,final_estimator=RandomForestRegressor(n_estimators=20))\n",
    "#STACK = STACK.fit(X_train, y_train)\n",
    "#pred2 = STACK.predict(X_test)\n",
    "#print(\"Accuracy on test set for STACK: %.2f\" % (r2_score(y_test, pred2)*100))\n",
    "\n",
    "#from joblib import dump, load\n",
    "#dump(VR, '95+_VR_RANDOM.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "68213ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = CatBoostRegressor()\\nparam_grid = {\\n    'learning_rate': [0.005,0.01,0.1,0.5,0.025,0.075],\\n    'depth': [4,10,15,25],\\n    'l2_leaf_reg': [1, 3, 5, 7]\\n}\\n\\nmodel, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \\n                                 param_grid, cv=5, scoring_fit='r2')\\n\\nprint(model.best_score_)\\nprint(model.best_params_)\\nprint(model.best_estimator_)\\n\\n\""
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = BayesianRidge()\n",
    "param_grid = {\n",
    "    'n_iter': [100],\n",
    "    'tol': [0.001,0.0005,0.01,0.1],\n",
    "    'alpha_1': [0.00001,0.000001,0.0000001,0.01],\n",
    "    'alpha_2': [10,1,0.1,0.01,0.001,0.0001],\n",
    "    'lambda_1': [0.000001,0.00001,0.0001,0.01,1],\n",
    "    'lambda_2': [0.000001,0.00001,0.0001,0.01,1]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\"\"\"\n",
    "model = LGBMRegressor()\n",
    "param_grid = {\n",
    "    'num_leaves': [40,30,20,50,60],\n",
    "    'max_depth': [2,5,7,10,15,20,25],\n",
    "    'learning_rate': [0.005,0.01,0.1,0.5,0.025,0.075],\n",
    "    'n_estimators': [150,300,400,500]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\"\"\"\n",
    "\n",
    "#0.8153889400743916\n",
    "#{'learning_rate': 0.025, 'max_depth': 15, 'n_estimators': 500, 'num_leaves': 40}\n",
    "\n",
    "#########################################\n",
    "\n",
    "\"\"\"\n",
    "model = CatBoostRegressor()\n",
    "param_grid = {\n",
    "    'learning_rate': [0.005,0.01,0.1,0.5,0.025,0.075],\n",
    "    'depth': [4,10,15,25],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "                                 param_grid, cv=5, scoring_fit='r2')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d939c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set for VR2: 0.855\n",
      "Accuracy on test set for VR3: 0.856\n",
      "Accuracy on test set for VR4: 0.856\n"
     ]
    }
   ],
   "source": [
    "#scores = cross_val_score(SVR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for SVR: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "#scores = cross_val_score(DTR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for DTR: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "#scores = cross_val_score(KNR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for KNF: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "#scores = cross_val_score(RFR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for RFR: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "                           \n",
    "#scores = cross_val_score(ETR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for ETR: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "#scores = cross_val_score(XGB,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for XGB: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "#scores = cross_val_score(GBR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for GBR: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "#scores = cross_val_score(VR,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for VR: %.3f\" % (scores.mean()))\n",
    "\n",
    "\n",
    "#scores = cross_val_score(VR1,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for VR1: %.3f\" % (scores.mean()))\n",
    "\n",
    "\n",
    "scores = cross_val_score(VR2,X_train, y_train, cv=8, scoring='r2')\n",
    "print(\"Accuracy on test set for VR2: %.3f\" % (scores.mean()))\n",
    "\n",
    "scores = cross_val_score(VR3,X_train, y_train, cv=8, scoring='r2')\n",
    "print(\"Accuracy on test set for VR3: %.3f\" % (scores.mean()))\n",
    "\n",
    "scores = cross_val_score(VR4,X_train, y_train, cv=8, scoring='r2')\n",
    "print(\"Accuracy on test set for VR4: %.3f\" % (scores.mean()))\n",
    "\n",
    "#scores = cross_val_score(VR3,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for VR3: %.3f\" % (scores.mean()))\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "#scores = cross_val_score(STACK,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for STACK: %.3f\" % (scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "93865a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "#from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "#ADA = AdaBoostRegressor(base_estimator=ExtraTreesRegressor(n_estimators=100,max_depth=20,n_jobs=3,min_samples_split=2),n_estimators=200,learning_rate=0.5)\n",
    "#ADA = ADA.fit(X_train, y_train)\n",
    "#pred2 = ADA.predict(X_test)\n",
    "#print(\"Accuracy on test set for ADA: %.2f\" % (r2_score(y_test, pred2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1a8d9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = cross_val_score(ADA,X_train, y_train, cv=5, scoring='r2')\n",
    "#print(\"Accuracy on test set for ADA: %.3f\" % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4a9ada25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "#tsne = TSNE(n_components=2, random_state=42)\n",
    "#X_reduced = tsne.fit_transform(X)\n",
    "\n",
    "#plt.figure(figsize=(13,10))\n",
    "#plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=\"jet\")\n",
    "#plt.axis('off')\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b69a6",
   "metadata": {},
   "source": [
    "K-MEANS CLUSTERING (REDUKCJA WYMIAROWOŚCI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cc958f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.cluster import KMeans\\n\\npipeline = Pipeline([\\n    (\"kmeans\",KMeans(n_clusters=109)),\\n    (\"ETR\",ETR),\\n])\\n\\npipeline.fit(X_train, y_train)\\npred8 = pipeline.predict(X_test)\\nprint(\"Accuracy on test set for ETR: %.2f\" % (r2_score(y_test, pred8) * 100))\\n\\n'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\",KMeans(n_clusters=109)),\n",
    "    (\"ETR\",ETR),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred8 = pipeline.predict(X_test)\n",
    "print(\"Accuracy on test set for ETR: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "29d21f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npipeline = Pipeline([\\n    (\"kmeans\",KMeans(n_clusters=109)),\\n    (\"ETR\",XGB),\\n])\\n\\npipeline.fit(X_train, y_train)\\npred8 = pipeline.predict(X_test)\\nprint(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred8) * 100))\\n\\n'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\",KMeans(n_clusters=109)),\n",
    "    (\"ETR\",XGB),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred8 = pipeline.predict(X_test)\n",
    "print(\"Accuracy on test set for XGB: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "cee4fe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npipeline = Pipeline([\\n    (\"kmeans\",KMeans(n_clusters=109)),\\n    (\"ETR\",ETR),\\n])\\n\\npipeline.fit(X_train, y_train)\\npred8 = pipeline.predict(X_test)\\nprint(\"Accuracy on test set for KNR: %.2f\" % (r2_score(y_test, pred8) * 100))\\n\\n'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\",KMeans(n_clusters=109)),\n",
    "    (\"ETR\",ETR),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred8 = pipeline.predict(X_test)\n",
    "print(\"Accuracy on test set for KNR: %.2f\" % (r2_score(y_test, pred8) * 100))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cc3c6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "                           \n",
    "#scores = cross_val_score(pipeline,X_train, y_train, cv=8, scoring='r2')\n",
    "#print(\"Accuracy on test set for pipeline: %.3f\" % (scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
